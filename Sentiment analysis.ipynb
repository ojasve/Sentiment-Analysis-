{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of IMDB movie review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # Words that dont contribute that much to the meaning of the sentence -> Sentiment nutral\n",
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files from directory\n",
    "\n",
    "## Train\n",
    "\n",
    "\n",
    "Data set http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_pos=(\"aclImdb/train/pos/\")\n",
    "directory_neg=(\"aclImdb/train/neg/\")\n",
    "\n",
    "lst_pos = os.listdir(directory_pos)\n",
    "lst_neg = os.listdir(directory_neg)\n",
    "\n",
    "no_files_pos=len(lst_pos)\n",
    "no_files_neg=len(lst_neg)\n",
    "print(no_files_pos)\n",
    "print(no_files_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_text=[]\n",
    "for i in lst_pos:\n",
    "    file = open(directory_pos+i,encoding='utf-8').read()\n",
    "    pos_text.append(file)\n",
    "\n",
    "neg_text=[]\n",
    "for i in lst_neg:\n",
    "    file = open(directory_neg+i,encoding='utf-8').read()\n",
    "    neg_text.append(file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possitive=pd.DataFrame(data=list(zip(pos_text)),columns=[\"text\"],index=None)\n",
    "negative=pd.DataFrame(data=list(zip(neg_text)),columns=[\"text\"],index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 1)\n",
      "(12500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(possitive.shape)\n",
    "print(negative.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Sentiment Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possitive=possitive.assign(sentiment=1)\n",
    "negative=negative.assign(sentiment=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train = pd.concat([negative,possitive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "full_train = shuffle(full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>One of Disney's best films that I can enjoy wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>What can possibly said about this movie other ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>Deaf secretary Carla (Emmanuelle Devos) is bul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>I don't understand your objections to this mov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Sitting, Typing",
       " Nothing is the latest \"what i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>This movie is one of the best ever produced by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Although I am generally a proponent of the wel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>Pushing Daisies was a wonderful show. Much lik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12362</th>\n",
       "      <td>almost every review of this movie I'd seen was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>The film is severely awful and is demeaning to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "2135   One of Disney's best films that I can enjoy wa...          1\n",
       "11192  What can possibly said about this movie other ...          0\n",
       "11053  Deaf secretary Carla (Emmanuelle Devos) is bul...          1\n",
       "3579   I don't understand your objections to this mov...          1\n",
       "612    Sitting, Typing\n",
       " Nothing is the latest \"what i...          1\n",
       "8211   This movie is one of the best ever produced by...          1\n",
       "1823   Although I am generally a proponent of the wel...          0\n",
       "4006   Pushing Daisies was a wonderful show. Much lik...          1\n",
       "12362  almost every review of this movie I'd seen was...          1\n",
       "686    The film is severely awful and is demeaning to...          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "directory_pos_test=(\"C:/Users/ojasves/Desktop/1_DS2_EXAM3/Midterm3/aclImdb_v1/aclImdb/test/pos/\")\n",
    "directory_neg_test=(\"C:/Users/ojasves/Desktop/1_DS2_EXAM3/Midterm3/aclImdb_v1/aclImdb/test/neg/\")\n",
    "lst_pos_test= os.listdir(directory_pos_test)\n",
    "lst_neg_test= os.listdir(directory_neg_test)\n",
    "\n",
    "no_files_pos_test=len(lst_pos_test)\n",
    "no_files_neg_test=len(lst_neg_test)\n",
    "print(no_files_pos_test)\n",
    "print(no_files_neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_text_test=[]\n",
    "for i in lst_pos_test:\n",
    "    file_test = open(directory_pos_test+i,encoding='utf-8').read()\n",
    "    pos_text_test.append(file_test)\n",
    "\n",
    "neg_text_test=[]\n",
    "for i in lst_neg_test:\n",
    "    file_test = open(directory_neg_test+i,encoding='utf-8').read()\n",
    "    neg_text_test.append(file_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possitive_test=pd.DataFrame(data=list(zip(pos_text_test)),columns=[\"text\"],index=None)\n",
    "negative_test=pd.DataFrame(data=list(zip(neg_text_test)),columns=[\"text\"],index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 1)\n",
      "(12500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(possitive_test.shape)\n",
    "print(negative_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possitive_test=possitive_test.assign(sentiment=1)\n",
    "negative_test=negative_test.assign(sentiment=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_test = pd.concat([possitive_test,negative_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I saw this film on September 1st, 2005 in Indi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Maybe I'm reading into this too much, but I wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I felt this film did have many good qualities....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This movie is amazing because the fact that th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Quitting\" may be as much about exiting a pre-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  I went and saw this movie last night after bei...          1\n",
       "1  Actor turned director Bill Paxton follows up h...          1\n",
       "2  As a recreational golfer with some knowledge o...          1\n",
       "3  I saw this film in a sneak preview, and it is ...          1\n",
       "4  Bill Paxton has taken the true story of the 19...          1\n",
       "5  I saw this film on September 1st, 2005 in Indi...          1\n",
       "6  Maybe I'm reading into this too much, but I wo...          1\n",
       "7  I felt this film did have many good qualities....          1\n",
       "8  This movie is amazing because the fact that th...          1\n",
       "9  \"Quitting\" may be as much about exiting a pre-...          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "full_test = shuffle(full_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>When I first saw this film around 6 months ago...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>I am fifteen years old and have seen thirty-th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>Dennis Hopper must've been really hungry to do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>I do not find this show at all funny. I actual...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>Having seen most of the Coen Brothers previous...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12157</th>\n",
       "      <td>This is not the kind of movie that really meri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>That this film has such a low IMDb rating is n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>can someone please help me i missed the last v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>This screened at Sundance last night to a rece...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>This movie I watched back in 1981 when it came...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "10211  When I first saw this film around 6 months ago...          1\n",
       "3000   I am fifteen years old and have seen thirty-th...          1\n",
       "5740   Dennis Hopper must've been really hungry to do...          0\n",
       "1679   I do not find this show at all funny. I actual...          0\n",
       "6278   Having seen most of the Coen Brothers previous...          1\n",
       "12157  This is not the kind of movie that really meri...          1\n",
       "2097   That this film has such a low IMDb rating is n...          0\n",
       "2373   can someone please help me i missed the last v...          0\n",
       "9330   This screened at Sundance last night to a rece...          0\n",
       "7802   This movie I watched back in 1981 when it came...          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing - Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make lower case\n",
    "full_train.text_lower = full_train.text.apply(lambda x: x.lower())\n",
    "full_test.text_lower = full_test.text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove html tags\n",
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    clean_html = re.compile('<.*?>')\n",
    "    cleantext = re.sub(clean_html, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train[\"text_no_html\"] = full_train.text_lower.apply(lambda z:cleanhtml(z))\n",
    "full_test[\"text_no_html\"] = full_test.text_lower.apply(lambda z:cleanhtml(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_no_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>One of Disney's best films that I can enjoy wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>one of disney's best films that i can enjoy wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>What can possibly said about this movie other ...</td>\n",
       "      <td>0</td>\n",
       "      <td>what can possibly said about this movie other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>Deaf secretary Carla (Emmanuelle Devos) is bul...</td>\n",
       "      <td>1</td>\n",
       "      <td>deaf secretary carla (emmanuelle devos) is bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>I don't understand your objections to this mov...</td>\n",
       "      <td>1</td>\n",
       "      <td>i don't understand your objections to this mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Sitting, Typing",
       " Nothing is the latest \"what i...</td>\n",
       "      <td>1</td>\n",
       "      <td>sitting, typing",
       " nothing is the latest \"what i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "2135   One of Disney's best films that I can enjoy wa...          1   \n",
       "11192  What can possibly said about this movie other ...          0   \n",
       "11053  Deaf secretary Carla (Emmanuelle Devos) is bul...          1   \n",
       "3579   I don't understand your objections to this mov...          1   \n",
       "612    Sitting, Typing\n",
       " Nothing is the latest \"what i...          1   \n",
       "\n",
       "                                            text_no_html  \n",
       "2135   one of disney's best films that i can enjoy wa...  \n",
       "11192  what can possibly said about this movie other ...  \n",
       "11053  deaf secretary carla (emmanuelle devos) is bul...  \n",
       "3579   i don't understand your objections to this mov...  \n",
       "612    sitting, typing\n",
       " nothing is the latest \"what i...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_no_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>When I first saw this film around 6 months ago...</td>\n",
       "      <td>1</td>\n",
       "      <td>when i first saw this film around 6 months ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>I am fifteen years old and have seen thirty-th...</td>\n",
       "      <td>1</td>\n",
       "      <td>i am fifteen years old and have seen thirty-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>Dennis Hopper must've been really hungry to do...</td>\n",
       "      <td>0</td>\n",
       "      <td>dennis hopper must've been really hungry to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>I do not find this show at all funny. I actual...</td>\n",
       "      <td>0</td>\n",
       "      <td>i do not find this show at all funny. i actual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>Having seen most of the Coen Brothers previous...</td>\n",
       "      <td>1</td>\n",
       "      <td>having seen most of the coen brothers previous...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "10211  When I first saw this film around 6 months ago...          1   \n",
       "3000   I am fifteen years old and have seen thirty-th...          1   \n",
       "5740   Dennis Hopper must've been really hungry to do...          0   \n",
       "1679   I do not find this show at all funny. I actual...          0   \n",
       "6278   Having seen most of the Coen Brothers previous...          1   \n",
       "\n",
       "                                            text_no_html  \n",
       "10211  when i first saw this film around 6 months ago...  \n",
       "3000   i am fifteen years old and have seen thirty-th...  \n",
       "5740   dennis hopper must've been really hungry to do...  \n",
       "1679   i do not find this show at all funny. i actual...  \n",
       "6278   having seen most of the coen brothers previous...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove punctuation \n",
    "def clean_num(raw_text):\n",
    "    #cleantext = \"\".join([word.lower() for word in raw_text if word not in string.punctuation])\n",
    "    clean_punc = re.compile('([!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~])')\n",
    "    cleantext = re.sub(clean_punc,\"\", raw_text)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train[\"text_no_pun\"] = full_train.text_no_html.apply(lambda z:clean_num(z))\n",
    "full_test[\"text_no_pun\"] = full_test.text_no_html.apply(lambda z:clean_num(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_no_html</th>\n",
       "      <th>text_no_pun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>When I first saw this film around 6 months ago...</td>\n",
       "      <td>1</td>\n",
       "      <td>when i first saw this film around 6 months ago...</td>\n",
       "      <td>when i first saw this film around 6 months ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>I am fifteen years old and have seen thirty-th...</td>\n",
       "      <td>1</td>\n",
       "      <td>i am fifteen years old and have seen thirty-th...</td>\n",
       "      <td>i am fifteen years old and have seen thirtythr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>Dennis Hopper must've been really hungry to do...</td>\n",
       "      <td>0</td>\n",
       "      <td>dennis hopper must've been really hungry to do...</td>\n",
       "      <td>dennis hopper mustve been really hungry to do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>I do not find this show at all funny. I actual...</td>\n",
       "      <td>0</td>\n",
       "      <td>i do not find this show at all funny. i actual...</td>\n",
       "      <td>i do not find this show at all funny i actuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>Having seen most of the Coen Brothers previous...</td>\n",
       "      <td>1</td>\n",
       "      <td>having seen most of the coen brothers previous...</td>\n",
       "      <td>having seen most of the coen brothers previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12157</th>\n",
       "      <td>This is not the kind of movie that really meri...</td>\n",
       "      <td>1</td>\n",
       "      <td>this is not the kind of movie that really meri...</td>\n",
       "      <td>this is not the kind of movie that really meri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>That this film has such a low IMDb rating is n...</td>\n",
       "      <td>0</td>\n",
       "      <td>that this film has such a low imdb rating is n...</td>\n",
       "      <td>that this film has such a low imdb rating is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>can someone please help me i missed the last v...</td>\n",
       "      <td>0</td>\n",
       "      <td>can someone please help me i missed the last v...</td>\n",
       "      <td>can someone please help me i missed the last v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>This screened at Sundance last night to a rece...</td>\n",
       "      <td>0</td>\n",
       "      <td>this screened at sundance last night to a rece...</td>\n",
       "      <td>this screened at sundance last night to a rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>This movie I watched back in 1981 when it came...</td>\n",
       "      <td>1</td>\n",
       "      <td>this movie i watched back in 1981 when it came...</td>\n",
       "      <td>this movie i watched back in 1981 when it came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "10211  When I first saw this film around 6 months ago...          1   \n",
       "3000   I am fifteen years old and have seen thirty-th...          1   \n",
       "5740   Dennis Hopper must've been really hungry to do...          0   \n",
       "1679   I do not find this show at all funny. I actual...          0   \n",
       "6278   Having seen most of the Coen Brothers previous...          1   \n",
       "12157  This is not the kind of movie that really meri...          1   \n",
       "2097   That this film has such a low IMDb rating is n...          0   \n",
       "2373   can someone please help me i missed the last v...          0   \n",
       "9330   This screened at Sundance last night to a rece...          0   \n",
       "7802   This movie I watched back in 1981 when it came...          1   \n",
       "\n",
       "                                            text_no_html  \\\n",
       "10211  when i first saw this film around 6 months ago...   \n",
       "3000   i am fifteen years old and have seen thirty-th...   \n",
       "5740   dennis hopper must've been really hungry to do...   \n",
       "1679   i do not find this show at all funny. i actual...   \n",
       "6278   having seen most of the coen brothers previous...   \n",
       "12157  this is not the kind of movie that really meri...   \n",
       "2097   that this film has such a low imdb rating is n...   \n",
       "2373   can someone please help me i missed the last v...   \n",
       "9330   this screened at sundance last night to a rece...   \n",
       "7802   this movie i watched back in 1981 when it came...   \n",
       "\n",
       "                                             text_no_pun  \n",
       "10211  when i first saw this film around 6 months ago...  \n",
       "3000   i am fifteen years old and have seen thirtythr...  \n",
       "5740   dennis hopper mustve been really hungry to do ...  \n",
       "1679   i do not find this show at all funny i actuall...  \n",
       "6278   having seen most of the coen brothers previous...  \n",
       "12157  this is not the kind of movie that really meri...  \n",
       "2097   that this film has such a low imdb rating is n...  \n",
       "2373   can someone please help me i missed the last v...  \n",
       "9330   this screened at sundance last night to a rece...  \n",
       "7802   this movie i watched back in 1981 when it came...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_no_html</th>\n",
       "      <th>text_no_pun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>One of Disney's best films that I can enjoy wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>one of disney's best films that i can enjoy wa...</td>\n",
       "      <td>one of disneys best films that i can enjoy wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>What can possibly said about this movie other ...</td>\n",
       "      <td>0</td>\n",
       "      <td>what can possibly said about this movie other ...</td>\n",
       "      <td>what can possibly said about this movie other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>Deaf secretary Carla (Emmanuelle Devos) is bul...</td>\n",
       "      <td>1</td>\n",
       "      <td>deaf secretary carla (emmanuelle devos) is bul...</td>\n",
       "      <td>deaf secretary carla emmanuelle devos is bulli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>I don't understand your objections to this mov...</td>\n",
       "      <td>1</td>\n",
       "      <td>i don't understand your objections to this mov...</td>\n",
       "      <td>i dont understand your objections to this movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Sitting, Typing",
       " Nothing is the latest \"what i...</td>\n",
       "      <td>1</td>\n",
       "      <td>sitting, typing",
       " nothing is the latest \"what i...</td>\n",
       "      <td>sitting typing",
       " nothing is the latest what if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>This movie is one of the best ever produced by...</td>\n",
       "      <td>1</td>\n",
       "      <td>this movie is one of the best ever produced by...</td>\n",
       "      <td>this movie is one of the best ever produced by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Although I am generally a proponent of the wel...</td>\n",
       "      <td>0</td>\n",
       "      <td>although i am generally a proponent of the wel...</td>\n",
       "      <td>although i am generally a proponent of the wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>Pushing Daisies was a wonderful show. Much lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>pushing daisies was a wonderful show. much lik...</td>\n",
       "      <td>pushing daisies was a wonderful show much like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12362</th>\n",
       "      <td>almost every review of this movie I'd seen was...</td>\n",
       "      <td>1</td>\n",
       "      <td>almost every review of this movie i'd seen was...</td>\n",
       "      <td>almost every review of this movie id seen was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>The film is severely awful and is demeaning to...</td>\n",
       "      <td>0</td>\n",
       "      <td>the film is severely awful and is demeaning to...</td>\n",
       "      <td>the film is severely awful and is demeaning to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "2135   One of Disney's best films that I can enjoy wa...          1   \n",
       "11192  What can possibly said about this movie other ...          0   \n",
       "11053  Deaf secretary Carla (Emmanuelle Devos) is bul...          1   \n",
       "3579   I don't understand your objections to this mov...          1   \n",
       "612    Sitting, Typing\n",
       " Nothing is the latest \"what i...          1   \n",
       "8211   This movie is one of the best ever produced by...          1   \n",
       "1823   Although I am generally a proponent of the wel...          0   \n",
       "4006   Pushing Daisies was a wonderful show. Much lik...          1   \n",
       "12362  almost every review of this movie I'd seen was...          1   \n",
       "686    The film is severely awful and is demeaning to...          0   \n",
       "\n",
       "                                            text_no_html  \\\n",
       "2135   one of disney's best films that i can enjoy wa...   \n",
       "11192  what can possibly said about this movie other ...   \n",
       "11053  deaf secretary carla (emmanuelle devos) is bul...   \n",
       "3579   i don't understand your objections to this mov...   \n",
       "612    sitting, typing\n",
       " nothing is the latest \"what i...   \n",
       "8211   this movie is one of the best ever produced by...   \n",
       "1823   although i am generally a proponent of the wel...   \n",
       "4006   pushing daisies was a wonderful show. much lik...   \n",
       "12362  almost every review of this movie i'd seen was...   \n",
       "686    the film is severely awful and is demeaning to...   \n",
       "\n",
       "                                             text_no_pun  \n",
       "2135   one of disneys best films that i can enjoy wat...  \n",
       "11192  what can possibly said about this movie other ...  \n",
       "11053  deaf secretary carla emmanuelle devos is bulli...  \n",
       "3579   i dont understand your objections to this movi...  \n",
       "612    sitting typing\n",
       " nothing is the latest what if ...  \n",
       "8211   this movie is one of the best ever produced by...  \n",
       "1823   although i am generally a proponent of the wel...  \n",
       "4006   pushing daisies was a wonderful show much like...  \n",
       "12362  almost every review of this movie id seen was ...  \n",
       "686    the film is severely awful and is demeaning to...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove Stop words and Stemming\n",
    "def clean_text_1(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train[\"text_no_stop\"] = full_train.text_no_pun.apply(lambda z:clean_text_1(z))\n",
    "full_test[\"text_no_stop\"] = full_test.text_no_pun.apply(lambda z:clean_text_1(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train[\"text_no_stop\"] = full_train.text_no_stop.apply(lambda z: \" \".join(str(x) for x in z))\n",
    "full_test[\"text_no_stop\"] = full_test.text_no_stop.apply(lambda z:\" \".join(str(x) for x in z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_no_html</th>\n",
       "      <th>text_no_pun</th>\n",
       "      <th>text_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>When I first saw this film around 6 months ago...</td>\n",
       "      <td>1</td>\n",
       "      <td>when i first saw this film around 6 months ago...</td>\n",
       "      <td>when i first saw this film around 6 months ago...</td>\n",
       "      <td>first saw film around 6 month ago consid inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>I am fifteen years old and have seen thirty-th...</td>\n",
       "      <td>1</td>\n",
       "      <td>i am fifteen years old and have seen thirty-th...</td>\n",
       "      <td>i am fifteen years old and have seen thirtythr...</td>\n",
       "      <td>fifteen year old seen thirtythre sinatra film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>Dennis Hopper must've been really hungry to do...</td>\n",
       "      <td>0</td>\n",
       "      <td>dennis hopper must've been really hungry to do...</td>\n",
       "      <td>dennis hopper mustve been really hungry to do ...</td>\n",
       "      <td>denni hopper mustv realli hungri movi atroci s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>I do not find this show at all funny. I actual...</td>\n",
       "      <td>0</td>\n",
       "      <td>i do not find this show at all funny. i actual...</td>\n",
       "      <td>i do not find this show at all funny i actuall...</td>\n",
       "      <td>find show funni actual think much wors terribl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>Having seen most of the Coen Brothers previous...</td>\n",
       "      <td>1</td>\n",
       "      <td>having seen most of the coen brothers previous...</td>\n",
       "      <td>having seen most of the coen brothers previous...</td>\n",
       "      <td>seen coen brother previou film expect someth d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12157</th>\n",
       "      <td>This is not the kind of movie that really meri...</td>\n",
       "      <td>1</td>\n",
       "      <td>this is not the kind of movie that really meri...</td>\n",
       "      <td>this is not the kind of movie that really meri...</td>\n",
       "      <td>kind movi realli merit critic attent go win os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>That this film has such a low IMDb rating is n...</td>\n",
       "      <td>0</td>\n",
       "      <td>that this film has such a low imdb rating is n...</td>\n",
       "      <td>that this film has such a low imdb rating is n...</td>\n",
       "      <td>film low imdb rate surpris postenron era reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>can someone please help me i missed the last v...</td>\n",
       "      <td>0</td>\n",
       "      <td>can someone please help me i missed the last v...</td>\n",
       "      <td>can someone please help me i missed the last v...</td>\n",
       "      <td>someon pleas help miss last view moment dont w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>This screened at Sundance last night to a rece...</td>\n",
       "      <td>0</td>\n",
       "      <td>this screened at sundance last night to a rece...</td>\n",
       "      <td>this screened at sundance last night to a rece...</td>\n",
       "      <td>screen sundanc last night recept mute crowd cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>This movie I watched back in 1981 when it came...</td>\n",
       "      <td>1</td>\n",
       "      <td>this movie i watched back in 1981 when it came...</td>\n",
       "      <td>this movie i watched back in 1981 when it came...</td>\n",
       "      <td>movi watch back 1981 came although miss first ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "10211  When I first saw this film around 6 months ago...          1   \n",
       "3000   I am fifteen years old and have seen thirty-th...          1   \n",
       "5740   Dennis Hopper must've been really hungry to do...          0   \n",
       "1679   I do not find this show at all funny. I actual...          0   \n",
       "6278   Having seen most of the Coen Brothers previous...          1   \n",
       "12157  This is not the kind of movie that really meri...          1   \n",
       "2097   That this film has such a low IMDb rating is n...          0   \n",
       "2373   can someone please help me i missed the last v...          0   \n",
       "9330   This screened at Sundance last night to a rece...          0   \n",
       "7802   This movie I watched back in 1981 when it came...          1   \n",
       "\n",
       "                                            text_no_html  \\\n",
       "10211  when i first saw this film around 6 months ago...   \n",
       "3000   i am fifteen years old and have seen thirty-th...   \n",
       "5740   dennis hopper must've been really hungry to do...   \n",
       "1679   i do not find this show at all funny. i actual...   \n",
       "6278   having seen most of the coen brothers previous...   \n",
       "12157  this is not the kind of movie that really meri...   \n",
       "2097   that this film has such a low imdb rating is n...   \n",
       "2373   can someone please help me i missed the last v...   \n",
       "9330   this screened at sundance last night to a rece...   \n",
       "7802   this movie i watched back in 1981 when it came...   \n",
       "\n",
       "                                             text_no_pun  \\\n",
       "10211  when i first saw this film around 6 months ago...   \n",
       "3000   i am fifteen years old and have seen thirtythr...   \n",
       "5740   dennis hopper mustve been really hungry to do ...   \n",
       "1679   i do not find this show at all funny i actuall...   \n",
       "6278   having seen most of the coen brothers previous...   \n",
       "12157  this is not the kind of movie that really meri...   \n",
       "2097   that this film has such a low imdb rating is n...   \n",
       "2373   can someone please help me i missed the last v...   \n",
       "9330   this screened at sundance last night to a rece...   \n",
       "7802   this movie i watched back in 1981 when it came...   \n",
       "\n",
       "                                            text_no_stop  \n",
       "10211  first saw film around 6 month ago consid inter...  \n",
       "3000   fifteen year old seen thirtythre sinatra film ...  \n",
       "5740   denni hopper mustv realli hungri movi atroci s...  \n",
       "1679   find show funni actual think much wors terribl...  \n",
       "6278   seen coen brother previou film expect someth d...  \n",
       "12157  kind movi realli merit critic attent go win os...  \n",
       "2097   film low imdb rate surpris postenron era reall...  \n",
       "2373   someon pleas help miss last view moment dont w...  \n",
       "9330   screen sundanc last night recept mute crowd cl...  \n",
       "7802   movi watch back 1981 came although miss first ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wn = nltk.WordNetLemmatizer()\n",
    "# def lemmatizing(tokenized_text):\n",
    "#     text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "#     return text\n",
    "\n",
    "# data[\"body_text_lemmatized\"] = data[\"body_text_nostop\"].apply(lambda x:lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Vocabulary\n",
    "# vocab=open(\"C:/Users/ojasves/Desktop/1_DS2_EXAM3/Midterm3/aclImdb_v1/aclImdb/imdb.vocab\",encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokens_voab = re.split('\\W+',vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf - Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tfv = TfidfVectorizer(min_df=3,\n",
    "                      strip_accents='unicode', \n",
    "                      analyzer='word',\n",
    "                      token_pattern=r'\\w{1,}',\n",
    "                      max_features=2000,\n",
    "                      stop_words = 'english')\n",
    "\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(full_train.text_no_stop) + list(full_test.text_no_stop))\n",
    "xtrain_tfv =  tfv.transform(full_train.text_no_stop) \n",
    "xvalid_tfv = tfv.transform(full_test.text_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvalid_tfv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain=full_train.sentiment\n",
    "yvalid=full_test.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "* Logistic reg\n",
    "* Multinomial NB\n",
    "* Ada boost\n",
    "* Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logictic regression\n",
    "log_reg = LogisticRegression(C=1.0)\n",
    "log_reg.fit(xtrain_tfv, ytrain)\n",
    "predictions_log_reg= log_reg.predict(xvalid_tfv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression; Accuracy Score: 0.868 \n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression; Accuracy Score: %0.3f \"%metrics.accuracy_score(yvalid, predictions_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Report:\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.86      0.87     12500\n",
      "          1       0.86      0.88      0.87     12500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Report:\\n \\n\",classification_report(yvalid,predictions_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(xtrain_tfv, ytrain)\n",
    "predictions_MNB = MNB.predict(xvalid_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB ; Accuracy Score: 0.835 \n",
      "\n",
      " MultinomialNB Report:\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.83      0.84     12500\n",
      "          1       0.83      0.84      0.84     12500\n",
      "\n",
      "avg / total       0.84      0.84      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MultinomialNB ; Accuracy Score: %0.3f \"%metrics.accuracy_score(yvalid, predictions_MNB))\n",
    "print(\"\\n MultinomialNB Report:\\n \\n\",classification_report(yvalid,predictions_MNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators =5,max_depth=5,n_jobs=-1,)\n",
    "RFC.fit(xtrain_tfv, ytrain)\n",
    "predictions_RFC = RFC.predict(xvalid_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier ; Accuracy Score: 0.693 \n",
      "\n",
      " Random Forest Classifier Report:\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.55      0.64     12500\n",
      "          1       0.65      0.84      0.73     12500\n",
      "\n",
      "avg / total       0.71      0.69      0.69     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier ; Accuracy Score: %0.3f \"%metrics.accuracy_score(yvalid, predictions_RFC))\n",
    "print(\"\\n Random Forest Classifier Report:\\n \\n\",classification_report(yvalid,predictions_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ABC = AdaBoostClassifier(n_estimators =5, learning_rate=0.5)\n",
    "ABC.fit(xtrain_tfv, ytrain)\n",
    "predictions_ABC = ABC.predict(xvalid_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Classifier  ; Accuracy Score: 0.699 \n",
      "\n",
      " Ada Boost Classifier  Report:\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.53      0.64     12500\n",
      "          1       0.65      0.87      0.74     12500\n",
      "\n",
      "avg / total       0.72      0.70      0.69     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ada Boost Classifier  ; Accuracy Score: %0.3f \"%metrics.accuracy_score(yvalid, predictions_ABC))\n",
    "print(\"\\n Ada Boost Classifier  Report:\\n \\n\",classification_report(yvalid,predictions_ABC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866465</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.86396</td>\n",
       "      <td>0.89264</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.89300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.89205</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.89100</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.89310</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>4.008546e-04</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695170</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.86388</td>\n",
       "      <td>0.88999</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8646</td>\n",
       "      <td>0.89010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8618</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.88870</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.88975</td>\n",
       "      <td>0.266726</td>\n",
       "      <td>7.982018e-04</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555856</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.86388</td>\n",
       "      <td>0.88629</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.88745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.88500</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>0.88495</td>\n",
       "      <td>0.8606</td>\n",
       "      <td>0.88655</td>\n",
       "      <td>0.076925</td>\n",
       "      <td>7.477314e-04</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798106</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.85752</td>\n",
       "      <td>0.87349</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l1'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.87510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8558</td>\n",
       "      <td>0.87305</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.87245</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.87275</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>3.504023e-07</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "1       0.866465         0.002798          0.86396           0.89264       1   \n",
       "0       0.695170         0.002601          0.86388           0.88999       1   \n",
       "3       0.555856         0.002800          0.86388           0.88629     0.5   \n",
       "2       0.798106         0.002999          0.85752           0.87349     0.5   \n",
       "\n",
       "  param_penalty                       params  rank_test_score  \\\n",
       "1            l2    {'C': 1, 'penalty': 'l2'}                1   \n",
       "0            l1    {'C': 1, 'penalty': 'l1'}                2   \n",
       "3            l2  {'C': 0.5, 'penalty': 'l2'}                2   \n",
       "2            l1  {'C': 0.5, 'penalty': 'l1'}                4   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "1             0.8592             0.89300       ...                    0.8650   \n",
       "0             0.8646             0.89010       ...                    0.8618   \n",
       "3             0.8584             0.88745       ...                    0.8662   \n",
       "2             0.8566             0.87510       ...                    0.8558   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "1             0.89205             0.8748             0.89100   \n",
       "0             0.88965             0.8748             0.88870   \n",
       "3             0.88500             0.8744             0.88495   \n",
       "2             0.87305             0.8680             0.87245   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "1             0.8614             0.89310      0.028612    4.008546e-04   \n",
       "0             0.8592             0.88975      0.266726    7.982018e-04   \n",
       "3             0.8606             0.88655      0.076925    7.477314e-04   \n",
       "2             0.8538             0.87275      0.068058    3.504023e-07   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "1        0.005807         0.001036  \n",
       "0        0.005828         0.000995  \n",
       "3        0.005890         0.001126  \n",
       "2        0.005375         0.000978  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_reg_G = LogisticRegression()\n",
    "param = {'C': [1,0.5],\n",
    "        'penalty': [\"l1\",\"l2\"]}\n",
    "\n",
    "gs_log_reg = GridSearchCV(Log_reg_G, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs_log_reg.fit(xtrain_tfv, ytrain)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.86      0.87     12500\n",
      "          1       0.86      0.88      0.87     12500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_log_reg.predict(xvalid_tfv)\n",
    "print(classification_report(yvalid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.406511</td>\n",
       "      <td>0.114928</td>\n",
       "      <td>0.80832</td>\n",
       "      <td>0.93192</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 30}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80792</td>\n",
       "      <td>0.93568</td>\n",
       "      <td>0.80872</td>\n",
       "      <td>0.92816</td>\n",
       "      <td>0.247849</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.00376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.076832</td>\n",
       "      <td>0.119926</td>\n",
       "      <td>0.79592</td>\n",
       "      <td>0.85196</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 30}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.79608</td>\n",
       "      <td>0.85752</td>\n",
       "      <td>0.79576</td>\n",
       "      <td>0.84640</td>\n",
       "      <td>0.169396</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.00556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.132798</td>\n",
       "      <td>0.060964</td>\n",
       "      <td>0.77316</td>\n",
       "      <td>0.90684</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.77208</td>\n",
       "      <td>0.90936</td>\n",
       "      <td>0.77424</td>\n",
       "      <td>0.90432</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.00108</td>\n",
       "      <td>0.00252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372769</td>\n",
       "      <td>0.039976</td>\n",
       "      <td>0.76664</td>\n",
       "      <td>0.82448</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.76880</td>\n",
       "      <td>0.82944</td>\n",
       "      <td>0.76448</td>\n",
       "      <td>0.81952</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.00216</td>\n",
       "      <td>0.00496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3       2.406511         0.114928          0.80832           0.93192   \n",
       "1       1.076832         0.119926          0.79592           0.85196   \n",
       "2       1.132798         0.060964          0.77316           0.90684   \n",
       "0       0.372769         0.039976          0.76664           0.82448   \n",
       "\n",
       "  param_max_depth param_n_estimators                                 params  \\\n",
       "3              20                 30  {'max_depth': 20, 'n_estimators': 30}   \n",
       "1              10                 30  {'max_depth': 10, 'n_estimators': 30}   \n",
       "2              20                 10  {'max_depth': 20, 'n_estimators': 10}   \n",
       "0              10                 10  {'max_depth': 10, 'n_estimators': 10}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "3                1            0.80792             0.93568            0.80872   \n",
       "1                2            0.79608             0.85752            0.79576   \n",
       "2                3            0.77208             0.90936            0.77424   \n",
       "0                4            0.76880             0.82944            0.76448   \n",
       "\n",
       "   split1_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "3             0.92816      0.247849        0.006994         0.00040   \n",
       "1             0.84640      0.169396        0.020987         0.00016   \n",
       "2             0.90432      0.021488        0.001000         0.00108   \n",
       "0             0.81952      0.001998        0.001999         0.00216   \n",
       "\n",
       "   std_train_score  \n",
       "3          0.00376  \n",
       "1          0.00556  \n",
       "2          0.00252  \n",
       "0          0.00496  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 30],\n",
    "        'max_depth': [10, 20]}\n",
    "\n",
    "gs_RFC = GridSearchCV(RFC, param, cv=2, n_jobs=-1)\n",
    "gs_fit = gs_RFC.fit(xtrain_tfv, ytrain)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 30}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_RFC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.77      0.80     12500\n",
      "          1       0.79      0.85      0.82     12500\n",
      "\n",
      "avg / total       0.81      0.81      0.81     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_RFC.predict(xvalid_tfv)\n",
    "print(classification_report(yvalid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.726438</td>\n",
       "      <td>0.045572</td>\n",
       "      <td>0.76316</td>\n",
       "      <td>0.76812</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 20}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0.76830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.76720</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.76360</td>\n",
       "      <td>0.7574</td>\n",
       "      <td>0.76995</td>\n",
       "      <td>1.236992</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.002699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.819757</td>\n",
       "      <td>0.057763</td>\n",
       "      <td>0.75688</td>\n",
       "      <td>0.76093</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 20}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.76430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.75815</td>\n",
       "      <td>0.7698</td>\n",
       "      <td>0.75785</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.76490</td>\n",
       "      <td>0.149101</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.003050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.899852</td>\n",
       "      <td>0.034081</td>\n",
       "      <td>0.72600</td>\n",
       "      <td>0.72906</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7316</td>\n",
       "      <td>0.73050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>0.72515</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.72265</td>\n",
       "      <td>0.7224</td>\n",
       "      <td>0.73640</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.004790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.116246</td>\n",
       "      <td>0.030619</td>\n",
       "      <td>0.72348</td>\n",
       "      <td>0.72791</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 10}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>0.72680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7244</td>\n",
       "      <td>0.72560</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.72540</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>0.73180</td>\n",
       "      <td>0.274259</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.562965</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.71980</td>\n",
       "      <td>0.72367</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 20}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7280</td>\n",
       "      <td>0.72815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.72605</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.71785</td>\n",
       "      <td>0.7078</td>\n",
       "      <td>0.72350</td>\n",
       "      <td>0.108769</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.009684</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "8       6.726438         0.045572          0.76316           0.76812   \n",
       "5       7.819757         0.057763          0.75688           0.76093   \n",
       "3       3.899852         0.034081          0.72600           0.72906   \n",
       "6       4.116246         0.030619          0.72348           0.72791   \n",
       "2       7.562965         0.057585          0.71980           0.72367   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "8                   1                 20   \n",
       "5                 0.5                 20   \n",
       "3                 0.5                 10   \n",
       "6                   1                 10   \n",
       "2                 0.2                 20   \n",
       "\n",
       "                                       params  rank_test_score  \\\n",
       "8    {'learning_rate': 1, 'n_estimators': 20}                1   \n",
       "5  {'learning_rate': 0.5, 'n_estimators': 20}                2   \n",
       "3  {'learning_rate': 0.5, 'n_estimators': 10}                3   \n",
       "6    {'learning_rate': 1, 'n_estimators': 10}                4   \n",
       "2  {'learning_rate': 0.2, 'n_estimators': 20}                5   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "8             0.7648             0.76830       ...                    0.7624   \n",
       "5             0.7632             0.76430       ...                    0.7596   \n",
       "3             0.7316             0.73050       ...                    0.7252   \n",
       "6             0.7276             0.72680       ...                    0.7244   \n",
       "2             0.7280             0.72815       ...                    0.7260   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "8             0.76720             0.7762             0.76360   \n",
       "5             0.75815             0.7698             0.75785   \n",
       "3             0.72515             0.7352             0.72265   \n",
       "6             0.72560             0.7344             0.72540   \n",
       "2             0.72605             0.7290             0.71785   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "8             0.7574             0.76995      1.236992        0.008885   \n",
       "5             0.7448             0.76490      0.149101        0.010640   \n",
       "3             0.7224             0.73640      0.077548        0.006098   \n",
       "6             0.7164             0.73180      0.274259        0.005880   \n",
       "2             0.7078             0.72350      0.108769        0.007657   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "8        0.007390         0.002699  \n",
       "5        0.009569         0.003050  \n",
       "3        0.006896         0.004790  \n",
       "6        0.007294         0.002536  \n",
       "2        0.009684         0.003475  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC = AdaBoostClassifier()\n",
    "param = {'n_estimators': [10, 5,20],\n",
    "        'learning_rate': [0.2,0.5,1]}\n",
    "\n",
    "gs_ABC = GridSearchCV(ABC, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs_ABC.fit(xtrain_tfv, ytrain)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'n_estimators': 20}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ABC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.70      0.75     12500\n",
      "          1       0.74      0.84      0.78     12500\n",
      "\n",
      "avg / total       0.77      0.77      0.77     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_ABC.predict(xvalid_tfv)\n",
    "print(classification_report(yvalid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline - Grid search on log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=2000, min_df=3,\n",
       "          ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words='english', strip_accents='unicode', sublinear_tf=False,\n",
       "          token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_reg_G = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfv),\n",
    "    ('clf', Log_reg_G)])\n",
    "pipeline.steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=2000, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__C': [1, 0.5], 'clf__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'clf__C': [1,0.5],\n",
    "        'clf__penalty': [\"l1\",\"l2\"]}\n",
    "\n",
    "\n",
    "\n",
    "cv_grid = GridSearchCV(pipeline, param_grid = {\n",
    "    'clf__C': [1,0.5],\n",
    "    'clf__penalty': [\"l1\",\"l2\"]\n",
    "})\n",
    "\n",
    "cv_grid.fit(full_train.text_no_stop, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.820212</td>\n",
       "      <td>1.441850</td>\n",
       "      <td>0.86316</td>\n",
       "      <td>0.89358</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'l2'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859851</td>\n",
       "      <td>0.894396</td>\n",
       "      <td>0.863211</td>\n",
       "      <td>0.893916</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>0.892429</td>\n",
       "      <td>0.508181</td>\n",
       "      <td>0.080987</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.540794</td>\n",
       "      <td>1.406449</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'l1'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.860811</td>\n",
       "      <td>0.890076</td>\n",
       "      <td>0.858411</td>\n",
       "      <td>0.890976</td>\n",
       "      <td>0.866179</td>\n",
       "      <td>0.887449</td>\n",
       "      <td>0.208477</td>\n",
       "      <td>0.183064</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.316748</td>\n",
       "      <td>1.286484</td>\n",
       "      <td>0.86120</td>\n",
       "      <td>0.88688</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'clf__C': 0.5, 'clf__penalty': 'l2'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.856611</td>\n",
       "      <td>0.888336</td>\n",
       "      <td>0.862611</td>\n",
       "      <td>0.886475</td>\n",
       "      <td>0.864378</td>\n",
       "      <td>0.885829</td>\n",
       "      <td>0.127942</td>\n",
       "      <td>0.059062</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.296858</td>\n",
       "      <td>1.247472</td>\n",
       "      <td>0.85552</td>\n",
       "      <td>0.86964</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'clf__C': 0.5, 'clf__penalty': 'l1'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.856012</td>\n",
       "      <td>0.871535</td>\n",
       "      <td>0.850972</td>\n",
       "      <td>0.870515</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.866871</td>\n",
       "      <td>0.063384</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1       3.820212         1.441850          0.86316           0.89358   \n",
       "0       3.540794         1.406449          0.86180           0.88950   \n",
       "3       3.316748         1.286484          0.86120           0.88688   \n",
       "2       3.296858         1.247472          0.85552           0.86964   \n",
       "\n",
       "  param_clf__C param_clf__penalty                                 params  \\\n",
       "1            1                 l2    {'clf__C': 1, 'clf__penalty': 'l2'}   \n",
       "0            1                 l1    {'clf__C': 1, 'clf__penalty': 'l1'}   \n",
       "3          0.5                 l2  {'clf__C': 0.5, 'clf__penalty': 'l2'}   \n",
       "2          0.5                 l1  {'clf__C': 0.5, 'clf__penalty': 'l1'}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "1                1           0.859851            0.894396           0.863211   \n",
       "0                2           0.860811            0.890076           0.858411   \n",
       "3                3           0.856611            0.888336           0.862611   \n",
       "2                4           0.856012            0.871535           0.850972   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "1            0.893916           0.866419            0.892429      0.508181   \n",
       "0            0.890976           0.866179            0.887449      0.208477   \n",
       "3            0.886475           0.864378            0.885829      0.127942   \n",
       "2            0.870515           0.859578            0.866871      0.063384   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "1        0.080987        0.002681         0.000837  \n",
       "0        0.183064        0.003247         0.001496  \n",
       "3        0.059062        0.003324         0.001062  \n",
       "2        0.016363        0.003530         0.002002  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_grid.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1, 'clf__penalty': 'l2'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid .best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
